# -*- coding: utf-8 -*-
"""
Created on Tue Oct 18 14:39:42 2022

@author: jh
"""


import streamlit as st
from PIL import Image
import torch 
from transformers import AutoModelForPreTraining, PreTrainedTokenizerFast
from typing import Optional

device = torch.device('cpu')


#@st.cache(suppress_st_warning=True,ttl=1000) - ì†ë„ëŠ” ë¹ ë¥¸ë° ë™ì¼í•œ ì¬ìƒì„± ê²°ê³¼
def gpt(prompt, min, max, rept_penalty):
    
    tokenizer = PreTrainedTokenizerFast.from_pretrained("skt/kogpt2-base-v2",
                                    bos_token='</s>', eos_token='</s>', unk_token='<unk>',
                                    pad_token='<pad>', mask_token='<mask>') 
    
    
    model = AutoModelForPreTraining.from_pretrained("neu02r/base")
    #model.load_state_dict(torch.load('ë² ì´ìŠ¤ëª¨ë¸.pth', map_location=device))
    
    #ìƒì„±
    prompt_ids = tokenizer.encode(prompt)
    inp = torch.tensor(prompt_ids)[None].cpu()
    preds = model.generate(inp,              
                           min_length=min,
                           max_length=max,
                           do_sample = True,
                           pad_token_id=tokenizer.pad_token_id,
                           eos_token_id=tokenizer.eos_token_id,
                           bos_token_id=tokenizer.bos_token_id,
                           length_penalty = 1,
                           repetition_penalty=rept_penalty,       
                           use_cache=True
                          ) 
    output = tokenizer.decode(preds[0].cpu().numpy())
    
    #ëª¨ì–‘ ë‹¤ë“¬ê¸°
    output = output.replace('<yun>', '\n\n')
    if '</s>' in output:
        output = output.rstrip('</s>')
    else:
        output = output.splitlines(True)
        output = output[:-1]
        output =''.join(output)
        
    return output




def display():
    
    st.title('KoGPT2ë¥¼ ì´ìš©í•œ ì‹œ ìƒì„±')
    
    #ì‚¬ì´ë“œë°”
    st.sidebar.markdown("# ì˜µì…˜ ì„¤ì • ğŸˆ")
    
    min = st.sidebar.slider(label='ì‹œì˜ ìµœì†Œê¸¸ì´', min_value=50, max_value=150, value=80, step=1)
    max = st.sidebar.slider(label='ì‹œì˜ ìµœëŒ€ê¸¸ì´', min_value=150, max_value=512, value=200, step=1)
    rept_penalty = st.sidebar.slider(label='ë‹¨ì–´ë°˜ë³µ ì œí•œì •ë„', min_value=0.5, max_value=2.0, value=1.8, step=0.1)
   
    
    #í”„ë¡¬í”„íŠ¸
    prompt = st.text_area('', 'ë°©ì•ˆì— ë‚˜ë¹„ê°€ \nì˜¨ì  ë‚˜ì˜¤ë©´ ì¤„ë°”ê¿ˆí•˜ëŠ”ê²Œ ë³´ê¸°ì—” ì¢‹ì€ë° \
                          ì¸ìœ„ì ì¸ ì¡°ì‘ì´ë¼ ê·¸ëŒ€ë¡œ ê°€ëŠ”ê²Œ ì¢‹ì„ë“¯\
                          \nì´ì œ ì‹œì¸ë³„ëª¨ë¸ ë²„íŠ¼ì¶”ê°€, ì´ë¯¸ì§€ìº¡ì…”ë‹ ì—°ê²°,\
                          ?:ê¹ƒí—ˆë¸Œ + ìŠ¤íŠ¸ë¦¼ë¦¿ í´ë¼ìš°ë“œ (ë°°í¬)')
                          
    
    if st.button('ì‹œ ìƒì„±í•˜ê¸°'):
        output = gpt(prompt, min, max, rept_penalty)
        st.code(output.encode().decode('utf-8'), language='python')


    
        
    
 
  
if __name__ == '__main__':
    display()
